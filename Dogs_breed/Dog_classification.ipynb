{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWMC2LG78FJK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw54XlbS9Mqf"
      },
      "outputs": [],
      "source": [
        "(dataset, info) = tfds.load(\"oxford_iiit_pet\",\n",
        "                            with_info=True,\n",
        "                            as_supervised=True)\n",
        "\n",
        "train_ds = dataset['train']\n",
        "test_ds = dataset['test']\n",
        "\n",
        "class_names = info.features['label'].names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnloWntd9mOI"
      },
      "outputs": [],
      "source": [
        "dog_labels = tf.constant(\n",
        "    [i for i, name in enumerate(class_names) if name[0].islower()], dtype=tf.int64\n",
        ")\n",
        "\n",
        "def is_dog(image, label):\n",
        "    return tf.reduce_any(tf.equal(dog_labels, label))\n",
        "\n",
        "train_ds = train_ds.filter(is_dog)\n",
        "test_ds = test_ds.filter(is_dog)\n",
        "\n",
        "dog_class_names = [class_names[i] for i in dog_labels.numpy()]\n",
        "NUM_CLASSES = len(dog_class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeYafjBU9tx-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "label_map = {original_idx: new_idx for new_idx, original_idx in enumerate(dog_labels.numpy())}\n",
        "\n",
        "for i, (image, label) in enumerate(train_ds.take(6)):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(dog_class_names[label_map[label.numpy()]])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFloK_qu9zz-"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "label_table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(list(label_map.keys()), dtype=tf.int64),\n",
        "        values=tf.constant(list(label_map.values()), dtype=tf.int64)\n",
        "    ),\n",
        "    default_value=-1\n",
        ")\n",
        "\n",
        "valid_labels = tf.constant(list(label_map.keys()), dtype=tf.int64)\n",
        "\n",
        "def filter_valid(image, label):\n",
        "    return tf.reduce_any(tf.equal(label, valid_labels))\n",
        "\n",
        "train_raw = dataset['train'].filter(filter_valid)\n",
        "test_raw = dataset['test'].filter(filter_valid)\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = image / 255.0\n",
        "    remapped_label = label_table.lookup(label)\n",
        "    return image, remapped_label\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_count = info.splits['train'].num_examples\n",
        "test_count = info.splits['test'].num_examples\n",
        "\n",
        "train_ds = train_raw\n",
        "test_ds = test_raw\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .cache()\n",
        "    .shuffle(1000)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .repeat()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_ds = (\n",
        "    test_ds\n",
        "    .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .cache()\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snDK6F7C9_6g"
      },
      "outputs": [],
      "source": [
        "counter = Counter()\n",
        "\n",
        "for _, label in dataset['train']:   # ‚Üê NOT train_ds\n",
        "    counter[label.numpy()] += 1\n",
        "\n",
        "print(\"Class Distribution:\")\n",
        "for i in range(NUM_CLASSES):\n",
        "    print(dog_class_names[i], \":\", counter[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyQy5bQP9_7k"
      },
      "outputs": [],
      "source": [
        "def create_cnn_model(num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        # First Convolutional Block\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "        # Second Convolutional Block\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "        # Third Convolutional Block\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "        # Fourth Convolutional Block\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "        # Fifth Convolutional Block\n",
        "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "        # Global Average Pooling and Dense Layers\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evl-2Xf4-mvn"
      },
      "outputs": [],
      "source": [
        "# Create and compile the model\n",
        "model = create_cnn_model(NUM_CLASSES)\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I5XlfBn-0tm"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=60,\n",
        "    steps_per_epoch=train_count // BATCH_SIZE,\n",
        "    validation_steps=test_count // BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Tg0AtPwZ46p"
      },
      "outputs": [],
      "source": [
        "model.save(\"dog_breed_model.keras\")\n",
        "print(\"Model saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpSD27vdCfJO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh7Oyt5TCix9"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH1m7g0CCvZO"
      },
      "outputs": [],
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=dog_class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x-OiFzdC6Af"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(cm, cmap='Blues', annot=False, fmt='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci0VLin6DDaP"
      },
      "outputs": [],
      "source": [
        "def predict_and_display(index):\n",
        "    image, label = list(test_ds.unbatch())[index]\n",
        "    input_img = tf.expand_dims(image, axis=0)\n",
        "\n",
        "    probs = model.predict(input_img, verbose=0)[0]\n",
        "    pred_class = np.argmax(probs)\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"True: {dog_class_names[label.numpy()]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    # Show top 5 predictions\n",
        "    top_5_indices = np.argsort(probs)[-5:][::-1]\n",
        "    top_5_probs = probs[top_5_indices] * 100\n",
        "    top_5_names = [dog_class_names[i] for i in top_5_indices]\n",
        "\n",
        "    colors = ['green' if i == pred_class else 'blue' for i in range(5)]\n",
        "    plt.barh(range(5), top_5_probs, color=colors)\n",
        "    plt.yticks(range(5), top_5_names)\n",
        "    plt.xlabel('Probability (%)')\n",
        "    plt.title(f\"Predicted: {dog_class_names[pred_class]}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Test prediction\n",
        "predict_and_display(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_display(50)"
      ],
      "metadata": {
        "id": "Joz0BXjpqvSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_display(70)"
      ],
      "metadata": {
        "id": "83ASf4N3rlq7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}